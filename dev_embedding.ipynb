{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUtcvb3WuX7y5r3/PpXF8K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nirika-Lamichhane/Minor_Project-5-24-25-36-/blob/main/dev_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR7k7P8eSUuq",
        "outputId": "bffdf01c-41f8-42a5-c86d-e978c9b13194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive automatically\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports and dataset loading\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gensim\n",
        "import gensim\n",
        "# Path to my dataset in Drive\n",
        "dataset_path = \"/content/drive/MyDrive/data_4000.txt\"\n",
        "\n",
        "# Loading dataset and adding headers\n",
        "df = pd.read_csv(dataset_path, names=[\"comment\",\"generalized_target\",\"aspect\",\"sentiment\"])\n",
        "\n",
        "print(\"Dataset loaded with shape:\", df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrbFIKUjTtMk",
        "outputId": "962f18b1-ed04-4511-e5f6-39cace225146"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Dataset loaded with shape: (4076, 4)\n",
            "                                          comment generalized_target  \\\n",
            "0          नागरिक अधिकार अझै सुनिश्चित गरिएको छैन              सरकार   \n",
            "1          नागरिक अधिकार अझै सुनिश्चित गरिएको छैन      नागरिक अधिकार   \n",
            "2         सार्वजनिक स्वास्थ्य सेवामा सुधार भएको छ    स्वास्थ्य विभाग   \n",
            "3  भ्रष्टाचारको सामना गर्न कडा कदम चाल्न आवश्यक छ     भ्रष्ट अधिकारी   \n",
            "4            अर्थतन्त्रमा सुधारको संकेत देखिएको छ              नेपाल   \n",
            "\n",
            "       aspect sentiment  \n",
            "0  Governance   Neutral  \n",
            "1  Governance   Neutral  \n",
            "2     Service  Positive  \n",
            "3  Corruption  Positive  \n",
            "4     Economy  Positive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Character n-gram tokenizer\n",
        "def char_ngrams(text, n=3):\n",
        "    \"\"\"\n",
        "    Generate character n-grams from a given text.\n",
        "    Example: \"यो भिडियो\" with n=3 → [\"यो \", \"ो भ\", \" भिड\", \"िडि\", \"डियो\"]\n",
        "    \"\"\"\n",
        "    text = str(text).strip()\n",
        "    return [text[i:i+n] for i in range(len(text)-n+1)]\n",
        "\n",
        "# Quick test\n",
        "sample_text = \"यो भिडियो राम्रो छ\"\n",
        "print(\"Sample text:\", sample_text)\n",
        "print(\"Character 3-grams:\", char_ngrams(sample_text, n=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9fuutswVT5n",
        "outputId": "335efd1c-b1c8-45b5-dd2a-80b0395db462"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample text: यो भिडियो राम्रो छ\n",
            "Character 3-grams: ['यो ', 'ो भ', ' भि', 'भिड', 'िडि', 'डिय', 'ियो', 'यो ', 'ो र', ' रा', 'राम', 'ाम्', 'म्र', '्रो', 'रो ', 'ो छ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading FastText embeddings\n",
        "\n",
        "# Path to my FastText Nepali embeddings in Drive\n",
        "fasttext_path = \"/content/drive/MyDrive/cc.ne.300.vec.gz\"\n",
        "\n",
        "# Loading the embeddings (Word2Vec format)\n",
        "ft_model = gensim.models.KeyedVectors.load_word2vec_format(fasttext_path)\n",
        "\n",
        "# Quick checks\n",
        "print(\"Embedding dimension:\", ft_model.vector_size)\n",
        "print(\"Example vector for 'नेपाल':\", ft_model['नेपाल'][:10])  # show first 10 values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlaJ8DfgV03i",
        "outputId": "e7b0d2f1-0696-4f95-afed-881435e9925f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding dimension: 300\n",
            "Example vector for 'नेपाल': [ 0.0624  0.0787 -0.0008 -0.0082  0.0259  0.0453  0.0057 -0.0182 -0.0275\n",
            " -0.0363]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting comments into padded embedding matrices\n",
        "\n",
        "def embed_comment(comment, n=3, max_len=50):\n",
        "    \"\"\"\n",
        "    Convert a single comment into a fixed-length embedding matrix.\n",
        "    - Tokenize into character n-grams (default n=3).\n",
        "    - Map each n-gram to a FastText vector (300-dim).\n",
        "    - Pad or truncate to max_len tokens.\n",
        "    \"\"\"\n",
        "    ngrams = char_ngrams(comment, n)\n",
        "    vectors = []\n",
        "    for ng in ngrams:\n",
        "        if ng in ft_model:\n",
        "            vectors.append(ft_model[ng])\n",
        "        else:\n",
        "            vectors.append(np.zeros(ft_model.vector_size))\n",
        "    # Pad / truncate\n",
        "    if len(vectors) < max_len:\n",
        "        pad = [np.zeros(ft_model.vector_size)] * (max_len - len(vectors))\n",
        "        vectors.extend(pad)\n",
        "    else:\n",
        "        vectors = vectors[:max_len]\n",
        "    return np.array(vectors)\n",
        "\n",
        "# Building dataset embeddings\n",
        "X = np.stack([embed_comment(c) for c in df['comment']])\n",
        "\n",
        "# Converting sentiment labels to numeric\n",
        "y = df['sentiment'].map({\"positive\":0,\"neutral\":1,\"negative\":2}).values\n",
        "\n",
        "print(\"Embeddings shape:\", X.shape)   # (num_samples, max_len, 300)\n",
        "print(\"Labels shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820RnWOrfV5w",
        "outputId": "2ebc1b2a-b5ec-42bb-c44b-7e48a7d39b43"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (4076, 50, 300)\n",
            "Labels shape: (4076,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding aspect labels (categorical → numeric)\n",
        "aspect_map = {a:i for i,a in enumerate(df['aspect'].unique())}\n",
        "y_aspect = df['aspect'].map(aspect_map).values\n",
        "\n",
        "print(\"Aspect categories:\", aspect_map)\n",
        "print(\"Aspect labels shape:\", y_aspect.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8hEM2GJjqAr",
        "outputId": "7857a6c9-4d58-459d-c9df-0fb10102c118"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aspect categories: {'Governance': 0, 'Service': 1, 'Corruption': 2, 'Economy': 3, 'Policy': 4, 'Positive': 5, 'governance': 6, 'corruption': 7, 'economy': 8, 'service': 9, 'policy': 10}\n",
            "Aspect labels shape: (4076,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating BIO labels for targets\n",
        "\n",
        "# Defining BIO tag set\n",
        "bio_tags = {\"O\":0, \"B-TARGET\":1, \"I-TARGET\":2}\n",
        "\n",
        "def generate_bio(comment, target, n=3, max_len=50):\n",
        "    \"\"\"\n",
        "    Generate BIO labels for each n-gram token in a comment.\n",
        "    - If token overlaps with target string → B/I-TARGET\n",
        "    - Else → O\n",
        "    \"\"\"\n",
        "    ngrams = char_ngrams(comment, n)\n",
        "    labels = []\n",
        "    for ng in ngrams:\n",
        "        if target and ng in target:\n",
        "            # First occurrence → B-TARGET, subsequent → I-TARGET\n",
        "            if not labels or labels[-1] == bio_tags[\"O\"]:\n",
        "                labels.append(bio_tags[\"B-TARGET\"])\n",
        "            else:\n",
        "                labels.append(bio_tags[\"I-TARGET\"])\n",
        "        else:\n",
        "            labels.append(bio_tags[\"O\"])\n",
        "    # Padding / truncation\n",
        "    if len(labels) < max_len:\n",
        "        labels.extend([bio_tags[\"O\"]] * (max_len - len(labels)))\n",
        "    else:\n",
        "        labels = labels[:max_len]\n",
        "    return np.array(labels)\n",
        "\n",
        "# Building BIO label dataset\n",
        "y_bio = np.stack([generate_bio(c, t) for c,t in zip(df['comment'], df['generalized_target'])])\n",
        "\n",
        "print(\"BIO labels shape:\", y_bio.shape)   # (num_samples, max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CHPGT2Qj19e",
        "outputId": "d63fe5ae-51a7-4555-fbc9-c2347fb1ffa5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BIO labels shape: (4076, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving all outputs to Drive for use in another Module\n",
        "\n",
        "# Save embeddings and labels\n",
        "np.save(\"/content/drive/MyDrive/X.npy\", X)                # embeddings\n",
        "np.save(\"/content/drive/MyDrive/y_sentiment.npy\", y)      # sentiment labels\n",
        "np.save(\"/content/drive/MyDrive/y_aspect.npy\", y_aspect)  # aspect labels\n",
        "np.save(\"/content/drive/MyDrive/y_bio.npy\", y_bio)        # BIO labels\n",
        "\n",
        "print(\"✅ All outputs saved to Drive!\")\n",
        "print(\"Files created:\")\n",
        "print(\"- /content/drive/MyDrive/X.npy\")\n",
        "print(\"- /content/drive/MyDrive/y_sentiment.npy\")\n",
        "print(\"- /content/drive/MyDrive/y_aspect.npy\")\n",
        "print(\"- /content/drive/MyDrive/y_bio.npy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPJ4hy9WkX6k",
        "outputId": "e183ff4c-d7e8-43ea-e71a-5665b49351f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All outputs saved to Drive!\n",
            "Files created:\n",
            "- /content/drive/MyDrive/X.npy\n",
            "- /content/drive/MyDrive/y_sentiment.npy\n",
            "- /content/drive/MyDrive/y_aspect.npy\n",
            "- /content/drive/MyDrive/y_bio.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0P_ODMlRqq_m"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}